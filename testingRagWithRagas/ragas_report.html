<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>user_input</th>
      <th>retrieved_contexts</th>
      <th>reference_contexts</th>
      <th>response</th>
      <th>reference</th>
      <th>faithfulness</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>What role does ChatGPT play in changing how we interact with information and technology?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, SourceResourcesLearning CenterBlogCompanyOur StoryCareersPartnersNewsroomSecurity &amp; ComplianceContact UsLegalPrivacy PolicyTerms of UseCopyright © Descope Inc. All rights reserved.All systems operationalGithub Icon GreyLinkedin Icon GreyX Grey IconInstagram Grey LogoSlack Grey IconYoutube Grey IconBluesky SocialDescope - Go to homepageChat with SalesAnonymously - no Slack account requiredProductApp Use CasesAuthentication MethodsDevelopersResourcesCompanyLegalLeave a Descope reviewGithub Icon GreyLinkedin Icon GreyX Grey IconInstagram Grey LogoSlack Grey IconYoutube Grey IconBluesky SocialAll systems operationalCopyright © Descope Inc. All rights reserved., standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[What Is the Model Context Protocol (MCP) and How It WorksSkip to main contentArrow RightGet a complimentary copy of the 2025 Gartner Buyers Guide for CIAM. Let's go &gt;Log InUser CircleProductUse CasesDevelopersCustomersResourcesCompanyPricingSign upArrow RightBook a demoArrow RightIdentipediaArrow LeftWhat Is the Model Context Protocol (MCP) and How It Works April 7, 2025Copy linkShare on:Share on LinkedInShare on XShare on BluskyTable of ContentsLLM isolation &amp; the NxM problemOpen table of contentsTable of ContentsLLM isolation &amp; the NxM problemMCP architecture and core componentsHow MCP worksMCP client &amp; server ecosystemSecurity considerations for MCP serversConclusionIdentity and auth news.  Straight to your inbox.SubscribeLarge language models (LLMs) like Claude, ChatGPT, Gemini, and LlaMA have completely changed how we interact with information and technology. They can write eloquently, perform deep research, and solve increasingly complex problems. But while typical models excel]</td>
      <td>ChatGPT, as an AI model, plays a significant role in changing how we interact with information and technology by enabling more natural and conversational interactions with AI systems. It allows users to ask questions, seek information, and perform tasks using everyday language, making the interaction more intuitive and user-friendly. This can lead to increased efficiency, productivity, and accessibility in accessing and utilizing information and technology. Additionally, ChatGPT can potentially enhance the capabilities of AI assistants, making them more informed, helpful, and capable of navigating the complex digital world around us.</td>
      <td>Large language models (LLMs) like ChatGPT have completely changed how we interact with information and technology by enabling eloquent writing, deep research, and solving complex problems.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>What are the impacts of applications on information interaction and technology?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., important checkpoint against automated exploits. However, this protection depends on clear permission prompts that help users make informed decisions—and a transparent understanding of the proposed scopes.This responsibility largely falls on server developers, who should strictly follow the principle of least privilege. Ideally, MCP servers will request only the minimum access necessary for their functionality. This ensures servers aren’t accidentally exposed to sensitive data while strengthening resilience against supply chain attacks that leverage unsecured connections between different resources. You can learn more about customizing scopes in our OAuth scopes and provider tokens guide.ConclusionThe Model Context Protocol represents a significant leap in connecting LLMs to external systems, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables, can accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The gaming-focused messaging app Discord shares many similarities with Slack, and the MCP server integration is no different. This allows users to send and read messages, with automatic server and channel discovery for easier navigation.Docker: Enables natural language interaction with Docker to manage containers, volumes, and images. Intended for server admins and tinkerers, this abstracts Docker both local and remote engine management into a friendlier interface.HubSpot: This integration with ubiquitous CRM HubSpot allows users to list and create contacts, get recent engagements, and manage companies. While simple, this server provides a simple way to retrieve information for use with other tools.Security considerations for MCP serversMCP’s OAuth implementation using HTTP+SSE transport servers, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[have completely changed how we interact with information and technology. They can write eloquently, perform deep research, and solve increasingly complex problems. But while typical models excel at responding to natural language, they’ve been constrained by their isolation from real-world data and systems. The Model Context Protocol (MCP) addresses this challenge by providing a standardized way for LLMs to connect with external data sources and tools—essentially a “universal remote” for AI apps. Released by Anthropic as an open-source protocol, MCP builds on existing function calling by eliminating the need for custom integration between LLMs and other apps. This means developers can build more capable, context-aware applications without reinventing the wheel for each combination of AI model and external system.This guide explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration, and how you can begin using it to build]</td>
      <td>The impacts of applications on information interaction and technology can be significant. Applications, especially those utilizing technologies like the Model Context Protocol (MCP), can standardize how AI applications communicate with external systems and data sources. This standardization reduces development overhead, promotes interoperability, and fosters innovation within the community. Additionally, applications like those integrated with Slack, GitHub, Stripe, Discord, Docker, and HubSpot showcase how AI can interact with various tools and platforms, enabling tasks like reading and writing messages, automating processes, managing data, and more. These applications can streamline workflows, enhance productivity, and open up new possibilities for creativity and collaboration.</td>
      <td>Applications have completely changed how we interact with information and technology. They can write eloquently, perform deep research, and solve increasingly complex problems.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>What are the challenges faced by end users and developers in integrating LLMs like Anthropic's Sonnet 3.X models?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP has gained rapid adoption across numerous platforms, creating a diverse ecosystem of clients and servers that bridge the gap between LLMs and external tools.Examples of MCP clientsMCP clients vary widely, from desktop applications to development environments. Claude Desktop serves as Anthropic's first-party offering, providing comprehensive support for everything MCP can do. Several code editors and IDEs have adopted support for the protocol, including Zed (which surfaces prompts as slash commands), Cursor (with MCP tools in its Composer environment), Continue (an open-source AI code assistant for JetBrains and Visual Studio Code), and Sourcegraph Cody (which implements MCP through OpenCtx).Framework support has expanded to include integrations for Firebase Genkit, LangChain adapters, and platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, important checkpoint against automated exploits. However, this protection depends on clear permission prompts that help users make informed decisions—and a transparent understanding of the proposed scopes.This responsibility largely falls on server developers, who should strictly follow the principle of least privilege. Ideally, MCP servers will request only the minimum access necessary for their functionality. This ensures servers aren’t accidentally exposed to sensitive data while strengthening resilience against supply chain attacks that leverage unsecured connections between different resources. You can learn more about customizing scopes in our OAuth scopes and provider tokens guide.ConclusionThe Model Context Protocol represents a significant leap in connecting LLMs to external systems, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables]</td>
      <td>[and external system.This guide explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration, and how you can begin using it to build better AI apps that go beyond isolated chat interfaces.LLM isolation &amp; the NxM problemIt’s no secret that LLMs are remarkably capable, but they typically operate in isolation from real-world systems and current data. This creates two distinct but related challenges: one for end users, and one for developers and businesses.For everyday users, the isolation means a constant “copy and paste tango” to get relevant responses about recent data. This requires manually collecting information from various sources, feeding it into the LLM’s chat interface, and then extracting or applying the AI’s output elsewhere. While several models offer AI-powered web search, and Anthropic’s Sonnet 3.X models boast a Computer Use feature, they still lack direct integration with knowledge stores and tools.For devs]</td>
      <td>I don't have specific information on the challenges faced by end users and developers in integrating LLMs like Anthropic's Sonnet 3.X models.</td>
      <td>For end users, the isolation of LLMs like Anthropic's Sonnet 3.X models leads to a constant 'copy and paste tango' to obtain relevant responses about recent data, requiring manual collection and input of information. Developers and businesses face challenges in integrating these models with knowledge stores and tools, as they typically operate in isolation from real-world systems and current data.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>What challenges do developers and enterprises face with AI-powered web search integration?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, important checkpoint against automated exploits. However, this protection depends on clear permission prompts that help users make informed decisions—and a transparent understanding of the proposed scopes.This responsibility largely falls on server developers, who should strictly follow the principle of least privilege. Ideally, MCP servers will request only the minimum access necessary for their functionality. This ensures servers aren’t accidentally exposed to sensitive data while strengthening resilience against supply chain attacks that leverage unsecured connections between different resources. You can learn more about customizing scopes in our OAuth scopes and provider tokens guide.ConclusionThe Model Context Protocol represents a significant leap in connecting LLMs to external systems, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[While several models offer AI-powered web search, and Anthropic’s Sonnet 3.X models boast a Computer Use feature, they still lack direct integration with knowledge stores and tools.For devs and enterprises, the challenge is much more complex: the “NxM problem,” where N represents LLMs and M stands for tools. On the N side, there are many AI systems, and on the M side, there are countless systems. Each LLM provider has their own protocols to connect with external tools, making the potential integration points essentially endless. By breaking the NxM problem down, we can see it causes:Redundant development efforts: Dev teams will repeatedly solve the same integration issues for each new AI model or data source. For example, connecting ChatGPT with your knowledge stores requires starting from scratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs]</td>
      <td>I don't have specific information on challenges related to AI-powered web search integration.</td>
      <td>For devs and enterprises, the challenge is much more complex due to the 'NxM problem,' where N represents LLMs and M stands for tools. Each LLM provider has their own protocols to connect with external tools, leading to endless potential integration points. This causes redundant development efforts as dev teams repeatedly solve integration issues for each new AI model or data source. Additionally, excessive maintenance is required as tools, models, and APIs need to be managed.</td>
      <td>0.500000</td>
    </tr>
    <tr>
      <td>How does the lack of standardization in APIs impact AI system integration?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, SourceResourcesLearning CenterBlogCompanyOur StoryCareersPartnersNewsroomSecurity &amp; ComplianceContact UsLegalPrivacy PolicyTerms of UseCopyright © Descope Inc. All rights reserved.All systems operationalGithub Icon GreyLinkedin Icon GreyX Grey IconInstagram Grey LogoSlack Grey IconYoutube Grey IconBluesky SocialDescope - Go to homepageChat with SalesAnonymously - no Slack account requiredProductApp Use CasesAuthentication MethodsDevelopersResourcesCompanyLegalLeave a Descope reviewGithub Icon GreyLinkedin Icon GreyX Grey IconInstagram Grey LogoSlack Grey IconYoutube Grey IconBluesky SocialAll systems operationalCopyright © Descope Inc. All rights reserved., standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[scratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs will inevitably evolve, and business will want to stay on the cutting edge. The lack of standardization means an integration can potentially stop working because a tool or model is updated, or an old one is deprecated. Fragmented implementation: Different integrations may handle similar functions in totally unexpected ways, creating unpredictable or undesirable results. This fragmentation can lead to end user confusion or frustration as different developers and companies implement inconsistent integrations. However, it’s important to understand that MCP doesn’t solve the NxM problem by simply replacing the integration methods that came before. It connects AI apps to context while building on top of function calling—the primary method for calling APIs from LLMs—to make development simpler and]</td>
      <td>The lack of standardization in APIs can impact AI system integration by making it more challenging for AI applications to communicate with different tools and data sources. Without standardized APIs, developers may need to create custom integrations for each tool or platform, leading to increased development overhead, complexity, and potential errors. Standardization, like what the Model Communication Protocol (MCP) aims to achieve, can streamline the integration process, reduce silos, and promote interoperability, ultimately benefiting the entire community by making AI applications more efficient and effective.</td>
      <td>The lack of standardization in APIs can lead to excessive maintenance as tools, models, and APIs evolve, potentially causing integrations to stop working. Fragmented implementation due to different integrations handling functions in unexpected ways can result in end user confusion or frustration.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>What is the relationship between function calling and 'tool use' in AI integration development?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification, MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with]</td>
      <td>[the integration methods that came before. It connects AI apps to context while building on top of function calling—the primary method for calling APIs from LLMs—to make development simpler and more consistent. Relationship between function calling &amp; Model Context ProtocolFunction calling, which allows LLMs to invoke predetermined functions based on user requests, is a well-established feature of modern AI models. Sometimes referred to as “tool use,” function calling is not mutually exclusive with MCP; the new protocol simply standardizes how this API feature works. Without MCP, when you use a function call directly with an LLM API, you need to:Define model-specific function schemas, which are JSON descriptions of the function, acceptable parameters, and what it returns.Implement handlers (the actual code that executes when a function is called) for those functions.Create different implementations for each model you support.MCP standardizes this process by:Defining a consistent way to]</td>
      <td>In AI integration development, the relationship between function calling and 'tool use' is crucial for enabling AI applications to interact with external systems and perform tasks. When a user interacts with an AI application that supports the Machine Common Protocol (MCP), the AI app can make function calls to external tools through the MCP servers. These function calls allow the AI to access the capabilities offered by the external tools, retrieve information, perform actions, and provide responses back to the user. Essentially, function calling facilitates the seamless communication between the AI and external systems, enabling the AI to utilize various tools and resources to fulfill user requests.</td>
      <td>Function calling, sometimes referred to as 'tool use,' is a well-established feature of modern AI models. The new Model Context Protocol (MCP) standardizes how this API feature works, making development simpler and more consistent by defining a consistent way to invoke predetermined functions based on user requests.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>What is the purpose of GPT in AI integration?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, MCP has gained rapid adoption across numerous platforms, creating a diverse ecosystem of clients and servers that bridge the gap between LLMs and external tools.Examples of MCP clientsMCP clients vary widely, from desktop applications to development environments. Claude Desktop serves as Anthropic's first-party offering, providing comprehensive support for everything MCP can do. Several code editors and IDEs have adopted support for the protocol, including Zed (which surfaces prompts as slash commands), Cursor (with MCP tools in its Composer environment), Continue (an open-source AI code assistant for JetBrains and Visual Studio Code), and Sourcegraph Cody (which implements MCP through OpenCtx).Framework support has expanded to include integrations for Firebase Genkit, LangChain adapters, and platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including, SourceResourcesLearning CenterBlogCompanyOur StoryCareersPartnersNewsroomSecurity &amp; ComplianceContact UsLegalPrivacy PolicyTerms of UseCopyright © Descope Inc. All rights reserved.All systems operationalGithub Icon GreyLinkedin Icon GreyX Grey IconInstagram Grey LogoSlack Grey IconYoutube Grey IconBluesky SocialDescope - Go to homepageChat with SalesAnonymously - no Slack account requiredProductApp Use CasesAuthentication MethodsDevelopersResourcesCompanyLegalLeave a Descope reviewGithub Icon GreyLinkedin Icon GreyX Grey IconInstagram Grey LogoSlack Grey IconYoutube Grey IconBluesky SocialAll systems operationalCopyright © Descope Inc. All rights reserved.]</td>
      <td>[(the actual code that executes when a function is called) for those functions.Create different implementations for each model you support.MCP standardizes this process by:Defining a consistent way to specify tools (functions) across any AI system.Providing a protocol for discovering available tools and executing them.Creating a universal, plug-and-play format where any AI app can use any tool without custom integration code.You might be familiar with AI apps that use function calling, like Custom GPTs using GPT Actions. A Custom GPT can determine which API call resolves the user's prompt, create the necessary JSON, then make the API call with it. While this allows some purpose-built tooling, it’s bound to OpenAI’s ecosystem. MCP brings similar capabilities to any AI application that implements the protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server]</td>
      <td>I don't have specific information about the purpose of GPT in AI integration based on the provided context.</td>
      <td>You might be familiar with AI apps that use function calling, like Custom GPTs using GPT Actions. A Custom GPT can determine which API call resolves the user's prompt, create the necessary JSON, then make the API call with it. While this allows some purpose-built tooling, it’s bound to OpenAI’s ecosystem. MCP brings similar capabilities to any AI application that implements the protocol, regardless of the underlying model vendor.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>What is the Model Context Protocol (MCP) and how does it relate to identity and authentication?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification, the protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different programming languages connect with a wide range of dev tools. Similarly, the aim of MCP is to provide a universal way for AI applications to interact with external systems by standardizing context.Fig: MCP general architectureCore componentsMCP architecture consists of four primary elements:Fig: MCP core componentsHost application: LLMs that interact with users and initiate connections. This includes Claude Desktop, AI-enhanced IDEs like Cursor, and standard web-based LLM chat interfaces.MCP client: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds]</td>
      <td>[&lt;1-hop&gt;\n\nWhat Is the Model Context Protocol (MCP) and How It WorksSkip to main contentArrow RightGet a complimentary copy of the 2025 Gartner Buyers Guide for CIAM. Let's go &gt;Log InUser CircleProductUse CasesDevelopersCustomersResourcesCompanyPricingSign upArrow RightBook a demoArrow RightIdentipediaArrow LeftWhat Is the Model Context Protocol (MCP) and How It Works April 7, 2025Copy linkShare on:Share on LinkedInShare on XShare on BluskyTable of ContentsLLM isolation &amp; the NxM problemOpen table of contentsTable of ContentsLLM isolation &amp; the NxM problemMCP architecture and core componentsHow MCP worksMCP client &amp; server ecosystemSecurity considerations for MCP serversConclusionIdentity and auth news.  Straight to your inbox.SubscribeLarge language models (LLMs) like Claude, ChatGPT, Gemini, and LlaMA have completely changed how we interact with information and technology. They can write eloquently, perform deep research, and solve increasingly complex problems. But while typical models excel]</td>
      <td>I don't have information on how the Model Context Protocol (MCP) specifically relates to identity and authentication.</td>
      <td>The Model Context Protocol (MCP) is a system that works with large language models (LLMs) like Claude, ChatGPT, Gemini, and LlaMA to enhance interactions with information and technology. It plays a crucial role in ensuring security considerations for MCP servers, which are essential for identity and authentication processes within the ecosystem.</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <td>How does the MCP server address security considerations for AI integration developers?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[&lt;1-hop&gt;\n\nscratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs will inevitably evolve, and business will want to stay on the cutting edge. The lack of standardization means an integration can potentially stop working because a tool or model is updated, or an old one is deprecated. Fragmented implementation: Different integrations may handle similar functions in totally unexpected ways, creating unpredictable or undesirable results. This fragmentation can lead to end user confusion or frustration as different developers and companies implement inconsistent integrations. However, it’s important to understand that MCP doesn’t solve the NxM problem by simply replacing the integration methods that came before. It connects AI apps to context while building on top of function calling—the primary method for calling APIs from LLMs—to make development simpler and, &lt;2-hop&gt;\n\nWhile simple, this server provides a simple way to retrieve information for use with other tools.Security considerations for MCP serversMCP’s OAuth implementation using HTTP+SSE transport servers exhibits the same risks as standard OAuth flows. Developers should be vigilant about open redirect vulnerabilities, properly secure tokens, and implement PKCE for all authorization code flows. The current MCP authorization specification incorporates a subset of OAuth 2.1. This means that the core concerns remain unchanged, and familiarity with common OAuth misconfigurations can help developers avoid security gaps.Human-in-the-loop design is a critical element in protecting MCP server users. Clients must request explicit permission from the user before accessing tools or resources, placing an important checkpoint against automated exploits. However, this protection depends on clear permission prompts that help users make informed decisions—and a transparent understanding of the proposed]</td>
      <td>The provided context does not specifically address how the MCP server addresses security considerations for AI integration developers.</td>
      <td>The MCP server addresses security considerations for AI integration developers by implementing OAuth using HTTP+SSE transport servers, which require vigilance against open redirect vulnerabilities, secure token handling, and the use of PKCE for all authorization code flows. The authorization specification of MCP incorporates a subset of OAuth 2.1, maintaining core security concerns. Additionally, human-in-the-loop design is emphasized to protect MCP server users, requiring explicit permission from users before accessing tools or resources to prevent automated exploits.</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <td>What challenges do AI integration developers face in terms of excessive maintenance and redundant development efforts?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, important checkpoint against automated exploits. However, this protection depends on clear permission prompts that help users make informed decisions—and a transparent understanding of the proposed scopes.This responsibility largely falls on server developers, who should strictly follow the principle of least privilege. Ideally, MCP servers will request only the minimum access necessary for their functionality. This ensures servers aren’t accidentally exposed to sensitive data while strengthening resilience against supply chain attacks that leverage unsecured connections between different resources. You can learn more about customizing scopes in our OAuth scopes and provider tokens guide.ConclusionThe Model Context Protocol represents a significant leap in connecting LLMs to external systems, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables, can accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The gaming-focused messaging app Discord shares many similarities with Slack, and the MCP server integration is no different. This allows users to send and read messages, with automatic server and channel discovery for easier navigation.Docker: Enables natural language interaction with Docker to manage containers, volumes, and images. Intended for server admins and tinkerers, this abstracts Docker both local and remote engine management into a friendlier interface.HubSpot: This integration with ubiquitous CRM HubSpot allows users to list and create contacts, get recent engagements, and manage companies. While simple, this server provides a simple way to retrieve information for use with other tools.Security considerations for MCP serversMCP’s OAuth implementation using HTTP+SSE transport servers]</td>
      <td>[&lt;1-hop&gt;\n\ncontributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, &lt;2-hop&gt;\n\nscratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs will inevitably evolve, and business will want to stay on the cutting edge. The lack of standardization means an integration can potentially stop working because a tool or model is updated, or an old one is deprecated. Fragmented implementation: Different integrations may handle similar functions in totally unexpected ways, creating unpredictable or undesirable results. This fragmentation can lead to end user confusion or frustration as different developers and companies implement inconsistent integrations. However, it’s important to understand that MCP doesn’t solve the NxM problem by simply replacing the integration methods that came before. It connects AI apps to context while building on top of function calling—the primary method for calling APIs from LLMs—to make development simpler and, &lt;3-hop&gt;\n\nWhile several models offer AI-powered web search, and Anthropic’s Sonnet 3.X models boast a Computer Use feature, they still lack direct integration with knowledge stores and tools.For devs and enterprises, the challenge is much more complex: the “NxM problem,” where N represents LLMs and M stands for tools. On the N side, there are many AI systems, and on the M side, there are countless systems. Each LLM provider has their own protocols to connect with external tools, making the potential integration points essentially endless. By breaking the NxM problem down, we can see it causes:Redundant development efforts: Dev teams will repeatedly solve the same integration issues for each new AI model or data source. For example, connecting ChatGPT with your knowledge stores requires starting from scratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs]</td>
      <td>AI integration developers may face challenges related to excessive maintenance and redundant development efforts when working with Model Context Protocol (MCP) servers. These challenges can include:\n\n1. **Fragmented Ecosystem**: Before the standardization brought by MCP, developers had to create custom integrations for each tool or data source they wanted to connect to. This led to redundant development efforts as each integration had to be built from scratch.\n\n2. **Maintenance Overhead**: Without a standardized protocol like MCP, developers had to maintain multiple custom integrations, each with its own set of requirements and updates. This could lead to excessive maintenance efforts as changes in one integration might not be easily applicable to others.\n\n3. **Lack of Universalization**: Before MCP, AI applications had to use different methods to communicate with various tools and data sources, leading to a lack of universalization. This lack of standardization could result in developers having to constantly adapt their integrations to work with different systems.\n\nBy adopting MCP and its standardized approach to connecting AI applications with external systems, developers can reduce maintenance overhead and avoid redundant development efforts. This standardization streamlines the integration process and allows developers to focus on creating value-added features rather than constantly maintaining and updating integrations.</td>
      <td>AI integration developers face challenges related to excessive maintenance and redundant development efforts due to the NxM problem, where N represents AI systems and M stands for tools. This leads to redundant development efforts as dev teams repeatedly solve the same integration issues for each new AI model or data source. Additionally, excessive maintenance is a concern as tools, models, and APIs evolve, requiring developers to start from scratch with custom code for every additional AI system or tool, leading to increased development efforts and potential integration issues.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does MCP address the challenges of excessive maintenance and fragmented implementation in AI integrations?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, MCP has gained rapid adoption across numerous platforms, creating a diverse ecosystem of clients and servers that bridge the gap between LLMs and external tools.Examples of MCP clientsMCP clients vary widely, from desktop applications to development environments. Claude Desktop serves as Anthropic's first-party offering, providing comprehensive support for everything MCP can do. Several code editors and IDEs have adopted support for the protocol, including Zed (which surfaces prompts as slash commands), Cursor (with MCP tools in its Composer environment), Continue (an open-source AI code assistant for JetBrains and Visual Studio Code), and Sourcegraph Cody (which implements MCP through OpenCtx).Framework support has expanded to include integrations for Firebase Genkit, LangChain adapters, and platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization]</td>
      <td>[&lt;1-hop&gt;\n\nMCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, &lt;2-hop&gt;\n\nscratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs will inevitably evolve, and business will want to stay on the cutting edge. The lack of standardization means an integration can potentially stop working because a tool or model is updated, or an old one is deprecated. Fragmented implementation: Different integrations may handle similar functions in totally unexpected ways, creating unpredictable or undesirable results. This fragmentation can lead to end user confusion or frustration as different developers and companies implement inconsistent integrations. However, it’s important to understand that MCP doesn’t solve the NxM problem by simply replacing the integration methods that came before. It connects AI apps to context while building on top of function calling—the primary method for calling APIs from LLMs—to make development simpler and]</td>
      <td>MCP addresses the challenges of excessive maintenance and fragmented implementation in AI integrations by providing a standardized structure for requests, responses, and notifications through JSON-RPC 2.0. This standardization streamlines communication between AI applications and external systems, making it easier to integrate and maintain various tools and resources. Additionally, MCP's protocol handshake process ensures that MCP clients can easily discover the capabilities of different servers, register them, and make them available for use during conversations. This approach helps reduce the complexity and fragmentation often associated with integrating AI tools, leading to more efficient and seamless interactions between AI assistants and external systems.</td>
      <td>MCP addresses the challenges of excessive maintenance and fragmented implementation in AI integrations by connecting AI apps to context while building on top of function calling. This approach simplifies development and avoids the need for developers to start from scratch with custom code for each additional AI system or tool. By standardizing the integration process, MCP ensures that tools, models, and APIs can evolve without causing integration failures due to updates or deprecations. Additionally, MCP prevents fragmented implementation by providing a consistent method for handling similar functions across different integrations, reducing end user confusion and frustration.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does the Model Context Protocol (MCP) standardize the process of function execution across AI systems?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, the protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different programming languages connect with a wide range of dev tools. Similarly, the aim of MCP is to provide a universal way for AI applications to interact with external systems by standardizing context.Fig: MCP general architectureCore componentsMCP architecture consists of four primary elements:Fig: MCP core componentsHost application: LLMs that interact with users and initiate connections. This includes Claude Desktop, AI-enhanced IDEs like Cursor, and standard web-based LLM chat interfaces.MCP client: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[&lt;1-hop&gt;\n\nand platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including reference servers (created by the protocol maintainers as implementation examples), official integrations (maintained by companies for their platforms), and community servers (developed by independent contributors).Reference serversReference servers demonstrate core MCP functionality and serve as examples for developers building their own implementations. These servers, maintained by MCP project contributors, include fundamental integrations like:PostgreSQL: Allows interaction with PostgreSQL databases, executing read-only SQL queries on the connected system. The fact that all commands are deployed with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel, &lt;2-hop&gt;\n\nconnectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests. Here, the main draw is the potential for delegating payment concerns to customer-facing chatbots.JetBrains: Lets developers leverage AI assistance directly within JetBrains IDEs. This integration provides code exploration (i.e., reading the file), breakpoint setting, and terminal command execution through natural language. Apify: Through the use of over 4,000 Apify Actors, enables a wide range of functions including a RAG (Retrieval Augmented Generation) web browser, data scraping across multiple platforms, and content crawling.Community MCP serversThe community-driven ecosystem exemplifies how standardization can accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The, &lt;3-hop&gt;\n\n(the actual code that executes when a function is called) for those functions.Create different implementations for each model you support.MCP standardizes this process by:Defining a consistent way to specify tools (functions) across any AI system.Providing a protocol for discovering available tools and executing them.Creating a universal, plug-and-play format where any AI app can use any tool without custom integration code.You might be familiar with AI apps that use function calling, like Custom GPTs using GPT Actions. A Custom GPT can determine which API call resolves the user's prompt, create the necessary JSON, then make the API call with it. While this allows some purpose-built tooling, it’s bound to OpenAI’s ecosystem. MCP brings similar capabilities to any AI application that implements the protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server]</td>
      <td>The Model Context Protocol (MCP) standardizes the process of function execution across AI systems by providing a universal way for AI applications to interact with external systems. It uses a client-server architecture that allows different AI applications to connect with external tools and data sources in a standardized manner. MCP uses JSON-RPC 2.0 as the underlying message standard, providing a structured format for requests, responses, and notifications. By standardizing context and communication protocols, MCP reduces development overhead and enables interoperability among AI applications and external systems.</td>
      <td>The Model Context Protocol (MCP) standardizes the process of function execution across AI systems by defining a consistent way to specify tools (functions) and providing a protocol for discovering available tools and executing them. It creates a universal, plug-and-play format where any AI app can use any tool without custom integration code, allowing for different implementations for each supported model. This standardization enables AI applications to leverage function calling capabilities similar to Custom GPTs using GPT Actions, but without being bound to a specific ecosystem like OpenAI's.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does MCP accelerate adoption and creativity through enthusiast-maintained servers like Discord, Docker, and HubSpot?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, MCP has gained rapid adoption across numerous platforms, creating a diverse ecosystem of clients and servers that bridge the gap between LLMs and external tools.Examples of MCP clientsMCP clients vary widely, from desktop applications to development environments. Claude Desktop serves as Anthropic's first-party offering, providing comprehensive support for everything MCP can do. Several code editors and IDEs have adopted support for the protocol, including Zed (which surfaces prompts as slash commands), Cursor (with MCP tools in its Composer environment), Continue (an open-source AI code assistant for JetBrains and Visual Studio Code), and Sourcegraph Cody (which implements MCP through OpenCtx).Framework support has expanded to include integrations for Firebase Genkit, LangChain adapters, and platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization]</td>
      <td>[&lt;1-hop&gt;\n\nMCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, &lt;2-hop&gt;\n\ncan accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The gaming-focused messaging app Discord shares many similarities with Slack, and the MCP server integration is no different. This allows users to send and read messages, with automatic server and channel discovery for easier navigation.Docker: Enables natural language interaction with Docker to manage containers, volumes, and images. Intended for server admins and tinkerers, this abstracts Docker both local and remote engine management into a friendlier interface.HubSpot: This integration with ubiquitous CRM HubSpot allows users to list and create contacts, get recent engagements, and manage companies. While simple, this server provides a simple way to retrieve information for use with other tools.Security considerations for MCP serversMCP’s OAuth implementation using HTTP+SSE transport servers]</td>
      <td>I don't have information on enthusiast-maintained servers like Discord, Docker, and HubSpot in relation to MCP.</td>
      <td>MCP accelerates adoption and creativity through enthusiast-maintained servers like Discord, Docker, and HubSpot by offering a diverse range of needs and capabilities. Discord allows gaming-focused messaging with server integration, Docker enables natural language interaction for managing containers, volumes, and images, and HubSpot integration simplifies contact management and engagement tracking. These servers, maintained by enthusiasts, provide unique functionalities that cater to different user requirements, fostering adoption and creativity in utilizing AI models within real-world systems.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>How does the Model Context Protocol (MCP) contribute to standardization and integration within the AI application ecosystem?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization]</td>
      <td>[&lt;1-hop&gt;\n\nthe protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different programming languages connect with a wide range of dev tools. Similarly, the aim of MCP is to provide a universal way for AI applications to interact with external systems by standardizing context.Fig: MCP general architectureCore componentsMCP architecture consists of four primary elements:Fig: MCP core componentsHost application: LLMs that interact with users and initiate connections. This includes Claude Desktop, AI-enhanced IDEs like Cursor, and standard web-based LLM chat interfaces.MCP client: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds, &lt;2-hop&gt;\n\nconnectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests. Here, the main draw is the potential for delegating payment concerns to customer-facing chatbots.JetBrains: Lets developers leverage AI assistance directly within JetBrains IDEs. This integration provides code exploration (i.e., reading the file), breakpoint setting, and terminal command execution through natural language. Apify: Through the use of over 4,000 Apify Actors, enables a wide range of functions including a RAG (Retrieval Augmented Generation) web browser, data scraping across multiple platforms, and content crawling.Community MCP serversThe community-driven ecosystem exemplifies how standardization can accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The, &lt;3-hop&gt;\n\nstandardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>The Model Context Protocol (MCP) contributes to standardization and integration within the AI application ecosystem by providing a standardized structure for requests, responses, and notifications using JSON-RPC 2.0. This standardization allows for quick and seamless communication between AI applications and external systems. By universalizing how AI applications interact with tools and data sources, MCP reduces development overhead and promotes interoperability within the ecosystem. It helps in standardizing a fragmented ecosystem, potentially resolving the NxM problem, and enabling innovation that benefits the entire community rather than being siloed. Additionally, MCP facilitates the creation of production-ready connectors for immediate use, simplifies the discovery and integration of available tools through a planned registry, and enables sophisticated AI-to-AI collaboration through features like sampling capabilities.</td>
      <td>The Model Context Protocol (MCP) contributes to standardization and integration within the AI application ecosystem by providing a universal way for AI applications to interact with external systems. It uses a client-server architecture inspired by the Language Server Protocol (LSP) to connect different programming languages with various dev tools. MCP standardizes context, simplifying how AI applications communicate with tools and data sources, reducing development overhead, and fostering interoperability. The community-driven ecosystem of MCP servers showcases how standardization accelerates adoption and creativity, benefiting the entire community by resolving the NxM problem and promoting innovation.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does the MCP standardization aim to simplify the integration of tools like GitHub for AI applications?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, MCP has gained rapid adoption across numerous platforms, creating a diverse ecosystem of clients and servers that bridge the gap between LLMs and external tools.Examples of MCP clientsMCP clients vary widely, from desktop applications to development environments. Claude Desktop serves as Anthropic's first-party offering, providing comprehensive support for everything MCP can do. Several code editors and IDEs have adopted support for the protocol, including Zed (which surfaces prompts as slash commands), Cursor (with MCP tools in its Composer environment), Continue (an open-source AI code assistant for JetBrains and Visual Studio Code), and Sourcegraph Cody (which implements MCP through OpenCtx).Framework support has expanded to include integrations for Firebase Genkit, LangChain adapters, and platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[&lt;1-hop&gt;\n\nstandardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification, &lt;2-hop&gt;\n\nwith MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds context and capabilities, exposing specific functions to AI apps through MCP. Each standalone server typically focuses on a specific integration point, like GitHub for repository access or a PostgreSQL for database operations. Transport layer: The communication mechanism between clients and servers. MCP supports two primary transport methods:STDIO (Standard Input/Output): Mainly local integrations where the server runs in the same environment as the client.HTTP+SSE (Server-Sent Events): Remote connections, with HTTP for client requests and SS for server responses and streaming.All communication in MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an]</td>
      <td>The MCP standardization aims to simplify the integration of tools like GitHub for AI applications by providing a standardized structure for requests, responses, and notifications through JSON-RPC 2.0. This standardization allows for quick and seamless communication between AI applications and external systems like GitHub. By following the MCP protocol handshake process, where the client connects to configured MCP servers, discovers capabilities, and registers them for use, AI applications can easily interact with tools like GitHub without the need for custom integrations. Additionally, the MCP ecosystem bridges the gap between AI applications and external tools, reducing development overhead and creating a more interoperable ecosystem for innovation to benefit the entire community.</td>
      <td>The MCP standardization aims to simplify the integration of tools like GitHub for AI applications by introducing an official MCP registry, which will make it easier to discover and integrate available tools. Additionally, MCP servers, such as the one for GitHub, expose specific functions to AI apps through MCP, focusing on repository access or database operations, and use transport layers like STDIO and HTTP+SSE for communication.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does the Model Context Protocol (MCP) address the challenges of AI integration and what does it offer to developers?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification, the protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different programming languages connect with a wide range of dev tools. Similarly, the aim of MCP is to provide a universal way for AI applications to interact with external systems by standardizing context.Fig: MCP general architectureCore componentsMCP architecture consists of four primary elements:Fig: MCP core componentsHost application: LLMs that interact with users and initiate connections. This includes Claude Desktop, AI-enhanced IDEs like Cursor, and standard web-based LLM chat interfaces.MCP client: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds]</td>
      <td>[&lt;1-hop&gt;\n\nscratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs will inevitably evolve, and business will want to stay on the cutting edge. The lack of standardization means an integration can potentially stop working because a tool or model is updated, or an old one is deprecated. Fragmented implementation: Different integrations may handle similar functions in totally unexpected ways, creating unpredictable or undesirable results. This fragmentation can lead to end user confusion or frustration as different developers and companies implement inconsistent integrations. However, it’s important to understand that MCP doesn’t solve the NxM problem by simply replacing the integration methods that came before. It connects AI apps to context while building on top of function calling—the primary method for calling APIs from LLMs—to make development simpler and, &lt;2-hop&gt;\n\nhave completely changed how we interact with information and technology. They can write eloquently, perform deep research, and solve increasingly complex problems. But while typical models excel at responding to natural language, they’ve been constrained by their isolation from real-world data and systems. The Model Context Protocol (MCP) addresses this challenge by providing a standardized way for LLMs to connect with external data sources and tools—essentially a “universal remote” for AI apps. Released by Anthropic as an open-source protocol, MCP builds on existing function calling by eliminating the need for custom integration between LLMs and other apps. This means developers can build more capable, context-aware applications without reinventing the wheel for each combination of AI model and external system.This guide explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration, and how you can begin using it to build]</td>
      <td>The Model Context Protocol (MCP) addresses the challenges of AI integration by providing a standardized way for AI applications to interact with external systems. It standardizes the communication process between AI apps and various tools and data sources, reducing development overhead and creating a more interoperable ecosystem. By universalizing how AI applications talk to tools and data sources, MCP aims to resolve the NxM problem and create a more cohesive environment for innovation.\n\nFor developers, MCP offers the following benefits:\n1. Standardization: MCP provides a standardized structure for requests, responses, and notifications using JSON-RPC 2.0, making it easier for developers to integrate AI applications with external systems.\n2. Simplified Integration: MCP enables quick and seamless communication between AI apps and external systems, simplifying the integration process for developers.\n3. Production-Ready Integrations: MCP offers official integrations with popular tools like Slack, GitHub, and Stripe, providing developers with ready-to-use connectors for immediate use.\n4. Future Developments: MCP is continuously evolving, with plans for an official MCP registry to simplify tool discovery and integration, as well as the introduction of sampling capabilities for AI-to-AI collaboration.\n\nOverall, MCP streamlines the integration of AI applications with external systems, reduces</td>
      <td>The Model Context Protocol (MCP) addresses the challenges of AI integration by providing a standardized way for Large Language Models (LLMs) to connect with external data sources and tools, essentially acting as a 'universal remote' for AI applications. It eliminates the need for custom integration between LLMs and other apps, allowing developers to build more capable, context-aware applications without having to reinvent the wheel for each combination of AI model and external system.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does the Model Context Protocol (MCP) by Anthropic address the challenge of connecting AI models with external data sources and tools?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, MCP has gained rapid adoption across numerous platforms, creating a diverse ecosystem of clients and servers that bridge the gap between LLMs and external tools.Examples of MCP clientsMCP clients vary widely, from desktop applications to development environments. Claude Desktop serves as Anthropic's first-party offering, providing comprehensive support for everything MCP can do. Several code editors and IDEs have adopted support for the protocol, including Zed (which surfaces prompts as slash commands), Cursor (with MCP tools in its Composer environment), Continue (an open-source AI code assistant for JetBrains and Visual Studio Code), and Sourcegraph Cody (which implements MCP through OpenCtx).Framework support has expanded to include integrations for Firebase Genkit, LangChain adapters, and platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization]</td>
      <td>[&lt;1-hop&gt;\n\nWhile several models offer AI-powered web search, and Anthropic’s Sonnet 3.X models boast a Computer Use feature, they still lack direct integration with knowledge stores and tools.For devs and enterprises, the challenge is much more complex: the “NxM problem,” where N represents LLMs and M stands for tools. On the N side, there are many AI systems, and on the M side, there are countless systems. Each LLM provider has their own protocols to connect with external tools, making the potential integration points essentially endless. By breaking the NxM problem down, we can see it causes:Redundant development efforts: Dev teams will repeatedly solve the same integration issues for each new AI model or data source. For example, connecting ChatGPT with your knowledge stores requires starting from scratch with custom code. But with every additional AI system or tool, your devs have to do everything from the beginning each time—N multiplied by M.Excessive maintenance: Tools, models, and APIs, &lt;2-hop&gt;\n\nhave completely changed how we interact with information and technology. They can write eloquently, perform deep research, and solve increasingly complex problems. But while typical models excel at responding to natural language, they’ve been constrained by their isolation from real-world data and systems. The Model Context Protocol (MCP) addresses this challenge by providing a standardized way for LLMs to connect with external data sources and tools—essentially a “universal remote” for AI apps. Released by Anthropic as an open-source protocol, MCP builds on existing function calling by eliminating the need for custom integration between LLMs and other apps. This means developers can build more capable, context-aware applications without reinventing the wheel for each combination of AI model and external system.This guide explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration, and how you can begin using it to build]</td>
      <td>The Model Context Protocol (MCP) by Anthropic addresses the challenge of connecting AI models with external data sources and tools by providing a standardized structure for requests, responses, and notifications using JSON-RPC 2.0 as the underlying message standard. When a user interacts with an AI app that supports MCP, processes like protocol handshake, initial connection, capability discovery, and registration occur behind the scenes to enable seamless communication between the AI and external systems. This allows AI assistants like Claude Desktop to quickly and efficiently access and utilize tools and resources from external sources, such as Slack, GitHub, and Stripe, through the MCP servers. The MCP ecosystem has gained rapid adoption across various platforms, enabling a diverse range of clients and servers to bridge the gap between AI models and external tools, making AI assistants more informed and helpful in managing and navigating the digital world.</td>
      <td>The Model Context Protocol (MCP) by Anthropic addresses the challenge of connecting AI models with external data sources and tools by providing a standardized way for Large Language Models (LLMs) to interact with real-world data and systems. It acts as a universal remote for AI applications, eliminating the need for custom integration between LLMs and other apps. This allows developers to create more capable and context-aware applications without having to start from scratch for each combination of AI model and external system.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>What is the Model Context Protocol (MCP) and how does it enable capability discovery for AI integration developers?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification, the protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different programming languages connect with a wide range of dev tools. Similarly, the aim of MCP is to provide a universal way for AI applications to interact with external systems by standardizing context.Fig: MCP general architectureCore componentsMCP architecture consists of four primary elements:Fig: MCP core componentsHost application: LLMs that interact with users and initiate connections. This includes Claude Desktop, AI-enhanced IDEs like Cursor, and standard web-based LLM chat interfaces.MCP client: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds]</td>
      <td>[&lt;1-hop&gt;\n\nhave completely changed how we interact with information and technology. They can write eloquently, perform deep research, and solve increasingly complex problems. But while typical models excel at responding to natural language, they’ve been constrained by their isolation from real-world data and systems. The Model Context Protocol (MCP) addresses this challenge by providing a standardized way for LLMs to connect with external data sources and tools—essentially a “universal remote” for AI apps. Released by Anthropic as an open-source protocol, MCP builds on existing function calling by eliminating the need for custom integration between LLMs and other apps. This means developers can build more capable, context-aware applications without reinventing the wheel for each combination of AI model and external system.This guide explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration, and how you can begin using it to build, &lt;2-hop&gt;\n\nMCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with]</td>
      <td>The Model Context Protocol (MCP) is a standardized protocol that enables AI applications to interact with external systems in a seamless and efficient manner. It uses JSON-RPC 2.0 as the underlying message standard, providing a structured format for requests, responses, and notifications.\n\nOne of the key features of MCP is capability discovery, which allows AI integration developers to easily identify and utilize the tools and resources offered by external systems. When a user interacts with an AI app that supports MCP, the protocol handshake process occurs, where the client connects to configured MCP servers, asks for available capabilities, and registers them for use during conversations.\n\nThis capability discovery process simplifies the integration of external tools and data sources into AI applications, reducing development overhead and promoting interoperability within the ecosystem. MCP standardizes how AI applications communicate with external systems, making it easier for developers to leverage a wide range of tools and resources for their AI projects.</td>
      <td>The Model Context Protocol (MCP) is a standardized way for LLMs to connect with external data sources and tools, acting as a 'universal remote' for AI apps. It eliminates the need for custom integration between LLMs and other apps, allowing developers to build more capable, context-aware applications without redundant development efforts. MCP uses JSON-RPC 2.0 as the underlying message standard and enables capability discovery by having the client ask each server about the capabilities they offer, which are then registered and made available for the AI to use during interactions.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does the Discord integration within the MCP servers accelerate adoption and creativity?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests. Here, the main draw is the potential for delegating payment concerns to customer-facing chatbots.JetBrains: Lets developers leverage AI assistance directly within JetBrains IDEs. This integration provides code exploration (i.e., reading the file), breakpoint setting, and terminal command execution through natural language. Apify: Through the use of over 4,000 Apify Actors, enables a wide range of functions including a RAG (Retrieval Augmented Generation) web browser, data scraping across multiple platforms, and content crawling.Community MCP serversThe community-driven ecosystem exemplifies how standardization can accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The]</td>
      <td>[&lt;1-hop&gt;\n\nconnectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests. Here, the main draw is the potential for delegating payment concerns to customer-facing chatbots.JetBrains: Lets developers leverage AI assistance directly within JetBrains IDEs. This integration provides code exploration (i.e., reading the file), breakpoint setting, and terminal command execution through natural language. Apify: Through the use of over 4,000 Apify Actors, enables a wide range of functions including a RAG (Retrieval Augmented Generation) web browser, data scraping across multiple platforms, and content crawling.Community MCP serversThe community-driven ecosystem exemplifies how standardization can accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The, &lt;2-hop&gt;\n\ncan accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The gaming-focused messaging app Discord shares many similarities with Slack, and the MCP server integration is no different. This allows users to send and read messages, with automatic server and channel discovery for easier navigation.Docker: Enables natural language interaction with Docker to manage containers, volumes, and images. Intended for server admins and tinkerers, this abstracts Docker both local and remote engine management into a friendlier interface.HubSpot: This integration with ubiquitous CRM HubSpot allows users to list and create contacts, get recent engagements, and manage companies. While simple, this server provides a simple way to retrieve information for use with other tools.Security considerations for MCP serversMCP’s OAuth implementation using HTTP+SSE transport servers]</td>
      <td>The Discord integration within the MCP servers, maintained by enthusiasts in the community-driven ecosystem, accelerates adoption and creativity by showcasing how standardization can lead to a more diverse range of needs being met. By having community-driven servers like Discord, developers and users can explore different use cases, functionalities, and interactions that may not have been initially considered by official integrations. This diversity in offerings can spark innovation, encourage experimentation, and ultimately drive the adoption of MCP tools in various contexts.</td>
      <td>The Discord integration within the MCP servers accelerates adoption and creativity by providing a platform that is maintained by enthusiasts rather than businesses, catering to a diverse range of needs. This gaming-focused messaging app allows users to send and read messages, with automatic server and channel discovery for easier navigation, fostering a collaborative and interactive environment for users within the MCP servers.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does the Model Context Protocol (MCP) architecture address the challenges of AI integration and isolation faced by LLMs?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., MCP uses JSON-RPC 2.0 as the underlying message standard, providing a standardized structure for requests, responses, and notifications.How MCP worksWhen a user interacts with a host application (an AI app) that supports MCP, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a closer look at what happens when a user asks Claude Desktop to perform a task that invokes tools outside the chat window.Protocol handshakeInitial connection: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.Capability discovery: The client asks each server "What capabilities do you offer?" Each server responds with its available tools, resources, and prompts.Registration: The client registers these capabilities, making them available for the AI to use during your conversation.Fig: A mermaid chart created by Claude, demonstrating how Claude uses external tools with, MCP has gained rapid adoption across numerous platforms, creating a diverse ecosystem of clients and servers that bridge the gap between LLMs and external tools.Examples of MCP clientsMCP clients vary widely, from desktop applications to development environments. Claude Desktop serves as Anthropic's first-party offering, providing comprehensive support for everything MCP can do. Several code editors and IDEs have adopted support for the protocol, including Zed (which surfaces prompts as slash commands), Cursor (with MCP tools in its Composer environment), Continue (an open-source AI code assistant for JetBrains and Visual Studio Code), and Sourcegraph Cody (which implements MCP through OpenCtx).Framework support has expanded to include integrations for Firebase Genkit, LangChain adapters, and platforms like Superinterface, which helps developers build in-app AI assistants with MCP functionality.Examples of MCP serversThe MCP ecosystem comprises a diverse range of servers including, the protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different programming languages connect with a wide range of dev tools. Similarly, the aim of MCP is to provide a universal way for AI applications to interact with external systems by standardizing context.Fig: MCP general architectureCore componentsMCP architecture consists of four primary elements:Fig: MCP core componentsHost application: LLMs that interact with users and initiate connections. This includes Claude Desktop, AI-enhanced IDEs like Cursor, and standard web-based LLM chat interfaces.MCP client: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds]</td>
      <td>[&lt;1-hop&gt;\n\nthe protocol, regardless of the underlying model vendor.MCP architecture and core componentsThe Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different programming languages connect with a wide range of dev tools. Similarly, the aim of MCP is to provide a universal way for AI applications to interact with external systems by standardizing context.Fig: MCP general architectureCore componentsMCP architecture consists of four primary elements:Fig: MCP core componentsHost application: LLMs that interact with users and initiate connections. This includes Claude Desktop, AI-enhanced IDEs like Cursor, and standard web-based LLM chat interfaces.MCP client: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.MCP server: Adds, &lt;2-hop&gt;\n\nand external system.This guide explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration, and how you can begin using it to build better AI apps that go beyond isolated chat interfaces.LLM isolation &amp; the NxM problemIt’s no secret that LLMs are remarkably capable, but they typically operate in isolation from real-world systems and current data. This creates two distinct but related challenges: one for end users, and one for developers and businesses.For everyday users, the isolation means a constant “copy and paste tango” to get relevant responses about recent data. This requires manually collecting information from various sources, feeding it into the LLM’s chat interface, and then extracting or applying the AI’s output elsewhere. While several models offer AI-powered web search, and Anthropic’s Sonnet 3.X models boast a Computer Use feature, they still lack direct integration with knowledge stores and tools.For devs]</td>
      <td>The Model Context Protocol (MCP) architecture addresses the challenges of AI integration and isolation faced by Language Model Models (LLMs) by providing a standardized way for AI applications to interact with external systems. MCP uses a client-server architecture that allows LLMs to connect with MCP servers, which act as bridges to external tools and APIs. This standardized approach ensures that LLMs can easily access and utilize a wide range of external resources without the need for custom integrations for each tool. Additionally, MCP's architecture includes core components such as host applications, MCP clients, and MCP servers, which work together to facilitate seamless communication between LLMs and external systems while maintaining isolation and security.</td>
      <td>The Model Context Protocol (MCP) architecture addresses the challenges of AI integration and isolation faced by LLMs through a client-server architecture inspired by the Language Server Protocol (LSP). This architecture standardizes context and provides a universal way for AI applications to interact with external systems. The MCP architecture includes core components like the host application, MCP client integrated within the host application, and MCP server, which collectively facilitate seamless connections between LLMs and external systems, solving the challenges of isolation and integration in AI development.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>How does Token-Based Authentication work in the context of OAuth implementation and what risks should be considered?</td>
      <td>[with a read-only limitation showcases how to keep MCP tooling within specific parameters.Slack: Enables AI apps to read and write messages in Slack workspaces, add reactions, retrieve channel history, and more. While straightforward, this underscores the potential for MCP to retrieve information from a wide variety of sources, including popular messaging apps.GitHub: Supports a wide variety of actions, including automating processes (e.g., pushing code), extracting or analyzing data, and even building AI-based apps. While the launch version was limited, the current GitHub MCP server serves as a benchmark for how AI assistants can interact with external APIs. Official MCP integrationsThese servers are officially supported by the companies who own the tools. Integrations like these are production-ready connectors available for immediate use.Stripe: This integration can handle use cases like generating invoices, creating customers, or managing refunds through natural language requests., can accelerate adoption and creativity. The following servers are maintained by enthusiasts rather than businesses, which means they trend toward a more diverse range of needs.Discord: The gaming-focused messaging app Discord shares many similarities with Slack, and the MCP server integration is no different. This allows users to send and read messages, with automatic server and channel discovery for easier navigation.Docker: Enables natural language interaction with Docker to manage containers, volumes, and images. Intended for server admins and tinkerers, this abstracts Docker both local and remote engine management into a friendlier interface.HubSpot: This integration with ubiquitous CRM HubSpot allows users to list and create contacts, get recent engagements, and manage companies. While simple, this server provides a simple way to retrieve information for use with other tools.Security considerations for MCP serversMCP’s OAuth implementation using HTTP+SSE transport servers, contributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization, standardizing a fragmented ecosystem and potentially resolving the NxM problem. By universalizing how AI applications talk to tools and data sources, MCP reduces development overhead and enables a more interoperable ecosystem where innovation benefits the entire community—rather than remaining siloed.As MCP continues to progress as a standard, several new developments have appeared on the horizon:Official MCP registry: A maintainer-sanctioned registry for MCP servers is being planned, which will simplify discovery and integration of available tools. This centralized repository will make it easier for anyone (not just those willing to scour GitHub) to find a server matching their needs.Sampling capabilities: Though not yet fully supported in many clients, the sampling feature will enable servers to request completions from LLMs through the client. This essentially allows for sophisticated AI-to-AI collaboration while maintaining thorough human oversight.Authorization specification]</td>
      <td>[&lt;1-hop&gt;\n\nAuthentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreDescope - Go to homepageChat with SalesAnonymously - no Slack account requiredLeave a Descope reviewProductPlatform OverviewDescope FlowsIntegrationsChangelogDescope vs Auth0Descope vs Ping IdentityDescope vs Okta CISApp Use CasesPasswordlessIdentity FederationATO PreventionIdentity OrchestrationAuthentication MethodsSocial LoginsPasskeysMFABiometrics / WebAuthnMagic LinksSSOOpenID ConnectnOTPOne-Time PasswordsAuthenticator AppsPasswordsDevelopersDocsTutorialsCommunityOpen SourceResourcesLearning CenterBlogCompanyOur StoryCareersPartnersNewsroomSecurity &amp; ComplianceContact UsLegalPrivacy PolicyTerms of UseCopyright © Descope Inc. All rights reserved.All systems, &lt;2-hop&gt;\n\ncontributors can build equally viable, increasingly valuable options to make everyone’s lives better.As adoption continues to grow, we’ll likely see AI assistants that are not just more informed about a given context, but ones who are genuinely more helpful in managing and navigating the complex digital world around us.For more developer updates from the world of authentication, access control, and AI, subscribe to our blog or follow us on LinkedIn.Identity and auth news.  Straight to your inbox.SubscribeLiked what you saw?Check out these posts nextAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization Explained &amp; When to Use ItRead moreAuthentication basics | Mar 17, 2024What Is Token-Based Authentication &amp; How It Works Read moreAuthentication protocols &amp; standards | Feb 20, 2025What Is OAuth &amp; How Does It WorkRead moreAuthentication basics | Nov 22, 2024Fine-Grained Authorization]</td>
      <td>Token-Based Authentication in the context of OAuth implementation works by providing a token (access token) to a client after successful authentication. This token is then used by the client to access protected resources on behalf of the user without needing to expose the user's credentials. OAuth typically involves the exchange of an authorization code for an access token, which is then used to make API requests.\n\nRisks that should be considered with Token-Based Authentication in OAuth implementation include:\n\n1. **Token Security**: Access tokens must be securely stored and transmitted to prevent unauthorized access. If a token is compromised, an attacker could gain access to the user's data.\n\n2. **Token Expiration**: Access tokens have a limited lifespan to reduce the risk of unauthorized access. Proper token management, including refreshing tokens when they expire, is crucial to maintain security.\n\n3. **Token Scope**: Access tokens should have limited scopes to only allow access to the necessary resources. Overly permissive tokens could lead to unauthorized access to sensitive data.\n\n4. **Token Transmission**: Access tokens should be transmitted securely over HTTPS to prevent interception by attackers.\n\n5. **Token Revocation**: Proper mechanisms for revoking access tokens in case of a security breach or when a user revokes access are essential to maintain security</td>
      <td>Token-Based Authentication works in the context of OAuth implementation by providing secure access tokens that are used to authenticate and authorize users without exposing their credentials. Risks like open redirect vulnerabilities, securing tokens, and ensuring proper authorization code flows should be considered to protect server users through human-in-the-loop design and transparent permission prompts.</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>